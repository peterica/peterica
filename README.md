
###  🐱 github stats  

<div id="main" align="center">
    <img src="https://github-readme-stats.vercel.app/api?username=peterica&count_private=true&show_icons=true&theme=radical"
        style="height: auto; margin-left: 20px; margin-right: 20px; padding: 10px;"/>
    <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=peterica&layout=compact"   
        style="height: auto; margin-left: 20px; margin-right: 20px; padding: 10px;"/>
</div>

###  💁‍♀️ About Me  
<p align="center">
    <a href="https://peterica.tistory.com/"><img src="https://img.shields.io/badge/Blog-FF5722?style=flat-square&logo=Blogger&logoColor=white"/></a>
    <a href="mailto:ilovefran.ofm@gmail.com"><img src="https://img.shields.io/badge/Gmail-d14836?style=flat-square&logo=Gmail&logoColor=white&link=ilovefran.ofm@gmail.com"/></a>
</p>

<br>

### 📕 Latest Blog Posts   

<a href ="https://peterica.tistory.com/1006"> 트래픽 성장과 함께 진화한 Redis &middot; RabbitMQ &middot; Kafka 이야기 </a> <br>
<a href ="https://peterica.tistory.com/1005"> [AI] QAT(Quantization-Aware Training) &mdash; 양자화를 가장 똑똑하게 하는 방법 </a> <br>
<a href ="https://peterica.tistory.com/1004"> [AI] 온톨로지&middot;지식그래프 기반 AI 전환 전략 </a> <br>
<a href ="https://peterica.tistory.com/1003"> [AI] 실무 중심 LLM 활용의 핵심 </a> <br>
<a href ="https://peterica.tistory.com/1002"> [AI] LLM의 미래는 어디로 가는가? </a> <br>
<a href ="https://peterica.tistory.com/1001"> [AI] LLM 양자화 완전 정리: GPTQ / AWQ / GGUF / BNB 차이 + 비트 수와 메모리 관계 </a> <br>
